{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kwtBUCcK-Rl8",
        "outputId": "68ffdd30-a84f-421a-c78c-0a4be0b0f00d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.12/dist-packages (0.3.27)\n",
            "Collecting langchain-openai\n",
            "  Downloading langchain_openai-1.0.2-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting langchain-community\n",
            "  Downloading langchain_community-0.4.1-py3-none-any.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.12/dist-packages (1.109.1)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.12/dist-packages (1.2.1)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.72 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.3.79)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.3.11)\n",
            "Requirement already satisfied: langsmith>=0.1.17 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.4.40)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.11.10)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.0.44)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.32.4)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.12/dist-packages (from langchain) (6.0.3)\n",
            "INFO: pip is looking at multiple versions of langchain-openai to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting langchain-openai\n",
            "  Downloading langchain_openai-1.0.1-py3-none-any.whl.metadata (1.8 kB)\n",
            "  Downloading langchain_openai-1.0.0-py3-none-any.whl.metadata (1.8 kB)\n",
            "  Downloading langchain_openai-0.3.35-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: tiktoken<1.0.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-openai) (0.12.0)\n",
            "INFO: pip is looking at multiple versions of langchain-community to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting langchain-community\n",
            "  Downloading langchain_community-0.4-py3-none-any.whl.metadata (3.0 kB)\n",
            "  Downloading langchain_community-0.3.31-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting requests<3,>=2 (from langchain)\n",
            "  Downloading requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (3.13.2)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (8.5.0)\n",
            "Collecting dataclasses-json<0.7.0,>=0.6.7 (from langchain-community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.11.0)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.4.3)\n",
            "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.0.2)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai) (4.11.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.11.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.12/dist-packages (from openai) (4.15.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.22.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->openai) (3.11)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7.0,>=0.6.7->langchain-community)\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7.0,>=0.6.7->langchain-community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (2025.10.5)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (1.33)\n",
            "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (25.0)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (3.11.4)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (0.25.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (2.5.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.4)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken<1.0.0,>=0.7.0->langchain-openai) (2024.11.6)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<1.0.0,>=0.3.72->langchain) (3.0.0)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain-community)\n",
            "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Downloading langchain_openai-0.3.35-py3-none-any.whl (75 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.0/76.0 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_community-0.3.31-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m40.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading requests-2.32.5-py3-none-any.whl (64 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.7/64.7 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
            "Installing collected packages: requests, mypy-extensions, marshmallow, typing-inspect, dataclasses-json, langchain-openai, langchain-community\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.32.4\n",
            "    Uninstalling requests-2.32.4:\n",
            "      Successfully uninstalled requests-2.32.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed dataclasses-json-0.6.7 langchain-community-0.3.31 langchain-openai-0.3.35 marshmallow-3.26.1 mypy-extensions-1.1.0 requests-2.32.5 typing-inspect-0.9.0\n"
          ]
        }
      ],
      "source": [
        "#basic stuff :\n",
        "!pip install langchain langchain-openai langchain-community openai python-dotenv\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from dotenv import load_dotenv\n",
        "from google.colab import userdata\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "\n",
        "\n",
        "load_dotenv()\n",
        "NEBIUS_KEY = userdata.get(\"NEBIUS_API_KEY\")\n",
        "OPENAI_KEY = userdata.get(\"OPENAI_API_KEY\")\n",
        "NEBIUS_BASE = \"https://api.studio.nebius.com/v1\"\n",
        "\n",
        "llm = ChatOpenAI(\n",
        "    model=\"meta-llama/Meta-Llama-3.1-8B-Instruct\",\n",
        "    temperature=0.6,\n",
        "    max_tokens=512,\n",
        "    openai_api_base=NEBIUS_BASE,\n",
        "    openai_api_key=NEBIUS_KEY\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tm7naSC_-VAJ",
        "outputId": "f4722453-7c88-46a3-93ef-dadc74760b54"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2800840027.py:12: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import ChatOpenAI``.\n",
            "  llm = ChatOpenAI(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##react design pattern"
      ],
      "metadata": {
        "id": "ORDrZ9JVBlS1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wikipedia"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "31WP0eWkCNrD",
        "outputId": "463429e6-8b5f-4a1a-edd6-091916c28ea8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting wikipedia\n",
            "  Downloading wikipedia-1.4.0.tar.gz (27 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (from wikipedia) (4.13.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from wikipedia) (2.32.5)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2025.10.5)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->wikipedia) (2.8)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->wikipedia) (4.15.0)\n",
            "Building wheels for collected packages: wikipedia\n",
            "  Building wheel for wikipedia (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wikipedia: filename=wikipedia-1.4.0-py3-none-any.whl size=11678 sha256=73f5dc5cd0263a903f93712432da4e24b1394286f20fc55f28f39eee0af221de\n",
            "  Stored in directory: /root/.cache/pip/wheels/63/47/7c/a9688349aa74d228ce0a9023229c6c0ac52ca2a40fe87679b8\n",
            "Successfully built wikipedia\n",
            "Installing collected packages: wikipedia\n",
            "Successfully installed wikipedia-1.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain import hub\n",
        "prompt = hub.pull(\"hwchase17/react\")"
      ],
      "metadata": {
        "id": "VqWKqMfNDXzG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use the following format:\n",
        "\n",
        "Question: the input question you must answer\n",
        "Thought: you should always think about what to do\n",
        "Action: the action to take, should be one of [{tool_names}]\n",
        "Action Input: the input to the action\n",
        "Observation: the result of the action\n",
        "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
        "Thought: I now know the final answer\n",
        "Final Answer: the final answer to the original input question\n",
        "\n",
        "Begin!\n",
        "\n",
        "Question: {input}\n",
        "Thought:{agent_scratchpad}"
      ],
      "metadata": {
        "id": "N1qIl9mLEzf6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.agents import create_react_agent, AgentExecutor, load_tools\n",
        "\n",
        "# Load tools\n",
        "tools = load_tools([\"wikipedia\"])\n",
        "\n",
        "agent = create_react_agent(llm, tools, prompt =prompt)\n",
        "\n",
        "\n",
        "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
        "\n",
        "agent_executor.invoke({\"input\": \"who is hozier\"})\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-qvffj3rBkvd",
        "outputId": "900b6f52-db5e-4877-9ac0-8cb7c2bc29a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mThought: The question is asking for information about a person.\n",
            "Action: wikipedia\n",
            "Action Input: Hozier\u001b[0m\u001b[36;1m\u001b[1;3mPage: Hozier\n",
            "Summary: Andrew John Hozier-Byrne (born 17 March 1990), known professionally as Hozier ( HOH-zee-ər), is an Irish musician. His music primarily draws from folk, soul and blues, often using religious and literary themes and taking political or social justice stances.\n",
            "His debut single, \"Take Me to Church\" (2013), became a rock radio hit in the U.S., peaked at number two on the Billboard Hot 100 and was certified multi-platinum in several countries. His eponymous debut studio album (2014) has been certified 6× platinum in Ireland and multi-platinum in several other countries. His EP Nina Cried Power (2018), which featured the title track as a single, reached number one on the Billboard Adult Alternative Songs chart. His second album, Wasteland, Baby! (2019), debuted atop the Irish Albums Chart and the Billboard 200, and was certified gold in the U.S. In late 2022, Hozier collaborated with Bear McCreary on the song \"Blood Upon the Snow\" for the video game God of War: Ragnarök. His third studio album, Unreal Unearth (2023), was released on Rubyworks Records and debuted at number one on the Irish and UK charts. In 2024, he released the EP Unheard, which includes his first number-one single in Ireland, the US, and the UK, \"Too Sweet\". Time magazine named him one of the 100 most influential people in the world in 2025.\n",
            "\n",
            "Page: Hozier (album)\n",
            "Summary: Hozier is the debut studio album by Irish musician Hozier. It was released on 19 September 2014 by Island Records and Rubyworks Records. Before the album's release, he attracted attention from his 2013 and 2014 EPs Take Me to Church (2013) and From Eden (2014), which contained songs that were later included on the album. Hozier collaborated with producer Rob Kirwan during its recording. Hozier has been described as a blues, soul and indie rock album with elements of gospel, R&B and folk music.\n",
            "Hozier received positive reviews from music critics, many of whom praised Hozier's songwriting and vocal performance. The record was also commercially successful, reaching top ten positions in several countries, including Ireland, the United Kingdom, the United States, Canada, Australia, New Zealand, the Netherlands, Denmark and Sweden. Five of the album's singles—\"Take Me to Church\", \"From Eden\", \"Sedated\", \"Work Song\", and \"Someone New\"—charted in the top-50 of the Irish Singles Chart. The album's lead single, \"Take Me to Church\", was a huge success worldwide and also earned a nomination for Song of the Year at the 57th Annual Grammy Awards in 2015. Following the release of the record, \"Jackie and Wilson\" and \"Cherry Wine\" were released as the album's sixth and seventh singles, respectively.\n",
            "\n",
            "Page: Hozier discography\n",
            "Summary: Irish singer-songwriter and musician Hozier has released 3 studio albums, 8 EPs, and 24 singles (including one as a featured artist). His debut studio album, Hozier, was released in September 2014. The album peaked at number one on the Irish Albums Chart. The album includes the singles \"Take Me to Church\", \"From Eden\", \"Sedated\", \"Work Song\", \"Someone New\", \"Jackie and Wilson\" and \"Cherry Wine\". \"Take Me to Church\" achieved widespread global popularity, topping the charts in twelve countries and reaching the top ten in twenty-one other territories. The song was nominated for the Grammy Award for Song of the Year at the 57th Annual Grammy Awards and has been certified diamond in the US. His second studio album, Wasteland, Baby!, was released in March 2019. The album peaked at number one on the Irish Albums Chart and the US Billboard 200. The album includes the singles \"Nina Cried Power\", \"Movement\", \"Almost (Sweet Music)\" and \"Dinner & Diatribes\". He released his third album Unreal Unearth in August 2023, which also topped the Irish Albums Chart and became his first number-one album in the UK.\u001b[0m\u001b[32;1m\u001b[1;3mThought: I now know that Hozier is an Irish musician, and I have information about his life, music, and discography.\n",
            "\n",
            "Final Answer: Hozier is an Irish musician.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input': 'who is hozier', 'output': 'Hozier is an Irish musician.'}"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Fake multi-agent"
      ],
      "metadata": {
        "id": "La4O4Pxv_BWg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.agents import initialize_agent, AgentType, load_tools\n",
        "\n",
        "# Create specialized agents\n",
        "research_tools = load_tools([\"wikipedia\"], llm=llm)\n",
        "math_tools = load_tools([\"llm-math\"], llm=llm)\n",
        "\n",
        "#for simplicity, lets use initialzie_agent, however we'd get similar results on using react agent + executor\n",
        "\n",
        "research_agent = initialize_agent(research_tools, llm, agent_type=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True)\n",
        "math_agent = initialize_agent(math_tools, llm, agent_type=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True)\n",
        "\n",
        "def coordinator(query):\n",
        "    \"\"\"Decide who handles what.\"\"\"\n",
        "    if \"calculate\" in query or \"*\" in query:\n",
        "        return math_agent.run(query)\n",
        "    return research_agent.run(query)\n",
        "\n",
        "print(coordinator(\"Who is the president of India?\"))\n",
        "print(coordinator(\"Calculate 345 * 23\"))\n"
      ],
      "metadata": {
        "id": "f28wyOAH-VQh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "biABkEXiBi-h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TLSOYiCpAeRi"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}