{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#TOOLS:"
      ],
      "metadata": {
        "id": "sVhOB9TqpmTw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##BUILDING USING LANGCHAIN'S BUILT-IN TOOLS:"
      ],
      "metadata": {
        "id": "kn2trqjLppMA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "iJYSyU_upboP",
        "outputId": "460e917e-4818-4ba0-8110-a4cc65bc7591"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.12/dist-packages (0.3.27)\n",
            "Collecting langchain-openai\n",
            "  Downloading langchain_openai-1.0.2-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting langchain-community\n",
            "  Downloading langchain_community-0.4.1-py3-none-any.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.12/dist-packages (1.109.1)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.12/dist-packages (1.2.1)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.72 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.3.79)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.3.11)\n",
            "Requirement already satisfied: langsmith>=0.1.17 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.4.40)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.11.10)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.0.44)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.32.4)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.12/dist-packages (from langchain) (6.0.3)\n",
            "INFO: pip is looking at multiple versions of langchain-openai to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting langchain-openai\n",
            "  Downloading langchain_openai-1.0.1-py3-none-any.whl.metadata (1.8 kB)\n",
            "  Downloading langchain_openai-1.0.0-py3-none-any.whl.metadata (1.8 kB)\n",
            "  Downloading langchain_openai-0.3.35-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: tiktoken<1.0.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-openai) (0.12.0)\n",
            "INFO: pip is looking at multiple versions of langchain-community to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting langchain-community\n",
            "  Downloading langchain_community-0.4-py3-none-any.whl.metadata (3.0 kB)\n",
            "  Downloading langchain_community-0.3.31-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting requests<3,>=2 (from langchain)\n",
            "  Downloading requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (3.13.2)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (8.5.0)\n",
            "Collecting dataclasses-json<0.7.0,>=0.6.7 (from langchain-community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.11.0)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.4.3)\n",
            "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.0.2)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai) (4.11.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.11.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.12/dist-packages (from openai) (4.15.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.22.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->openai) (3.11)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7.0,>=0.6.7->langchain-community)\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7.0,>=0.6.7->langchain-community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (2025.10.5)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (1.33)\n",
            "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (25.0)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (3.11.4)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (0.25.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (2.5.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.4)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken<1.0.0,>=0.7.0->langchain-openai) (2024.11.6)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<1.0.0,>=0.3.72->langchain) (3.0.0)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain-community)\n",
            "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Downloading langchain_openai-0.3.35-py3-none-any.whl (75 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.0/76.0 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_community-0.3.31-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m31.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading requests-2.32.5-py3-none-any.whl (64 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.7/64.7 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
            "Installing collected packages: requests, mypy-extensions, marshmallow, typing-inspect, dataclasses-json, langchain-openai, langchain-community\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.32.4\n",
            "    Uninstalling requests-2.32.4:\n",
            "      Successfully uninstalled requests-2.32.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed dataclasses-json-0.6.7 langchain-community-0.3.31 langchain-openai-0.3.35 marshmallow-3.26.1 mypy-extensions-1.1.0 requests-2.32.5 typing-inspect-0.9.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "requests"
                ]
              },
              "id": "39431a877b69430e9877999125370a44"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "#basic stuff :\n",
        "!pip install langchain langchain-openai langchain-community openai python-dotenv\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "import os\n",
        "\n",
        "# Fetch your stored Colab secrets\n",
        "NEBIUS_KEY = userdata.get(\"NEBIUS_API_KEY\")\n",
        "OPENAI_KEY = userdata.get(\"OPENAI_API_KEY\")\n",
        "\n",
        "# Check what loaded (safe because values are hidden)\n",
        "print(\"NEBIUS_KEY found:\", bool(NEBIUS_KEY))\n",
        "print(\"OPENAI_KEY found:\", bool(OPENAI_KEY))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZlC7R5blpuhK",
        "outputId": "eb32bdea-4a12-4bc5-c803-832d8e1d479b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NEBIUS_KEY found: True\n",
            "OPENAI_KEY found: True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from dotenv import load_dotenv\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "\n",
        "load_dotenv()\n",
        "# Assign them to env vars so LangChain’s validation passes\n",
        "os.environ[\"NEBIUS_API_KEY\"] = NEBIUS_KEY\n",
        "os.environ[\"OPENAI_API_KEY\"] = OPENAI_KEY or NEBIUS_KEY  # LangChain needs this\n",
        "\n",
        "NEBIUS_BASE = \"https://api.studio.nebius.com/v1\"\n",
        "\n",
        "llm = ChatOpenAI(\n",
        "    model=\"meta-llama/Meta-Llama-3.1-8B-Instruct\",\n",
        "    temperature=0.6,\n",
        "    max_tokens=512,\n",
        "    openai_api_base=NEBIUS_BASE,\n",
        "    openai_api_key=NEBIUS_KEY\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pxU5NyoLqOKr",
        "outputId": "da4a2fb9-fdf4-4771-b69e-08e62eb80be0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-547857652.py:12: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import ChatOpenAI``.\n",
            "  llm = ChatOpenAI(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Real stuff :"
      ],
      "metadata": {
        "id": "rB6LBlDkqsmJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.agents import initialize_agent, load_tools\n"
      ],
      "metadata": {
        "id": "1T8kgsjHqsPK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##USING WIKIPEDIA TOOL\n",
        "LangChain’s \"wikipedia\" tool is just a wrapper around the separate open-source wikipedia Python module."
      ],
      "metadata": {
        "id": "HqIJzw9urEt8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wikipedia\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cIupDDROrO6W",
        "outputId": "75ef49a3-df9c-4ae6-e7c2-87f42c451812"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting wikipedia\n",
            "  Downloading wikipedia-1.4.0.tar.gz (27 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (from wikipedia) (4.13.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from wikipedia) (2.32.5)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2025.10.5)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->wikipedia) (2.8)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->wikipedia) (4.15.0)\n",
            "Building wheels for collected packages: wikipedia\n",
            "  Building wheel for wikipedia (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wikipedia: filename=wikipedia-1.4.0-py3-none-any.whl size=11678 sha256=4f400ebb8aa385e582bff14c32b5fb4e381e6053a0c93f0b3f1c2909f93a1ff9\n",
            "  Stored in directory: /root/.cache/pip/wheels/63/47/7c/a9688349aa74d228ce0a9023229c6c0ac52ca2a40fe87679b8\n",
            "Successfully built wikipedia\n",
            "Installing collected packages: wikipedia\n",
            "Successfully installed wikipedia-1.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Directly import the fucntion, doesnt use any model:"
      ],
      "metadata": {
        "id": "YbQK6fK5rzxP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.utilities import WikipediaAPIWrapper\n",
        "\n",
        "wiki = WikipediaAPIWrapper()\n",
        "\n",
        "# simple summary for any query\n",
        "print(wiki.run(\"who is Kim K?\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FF24HQDirzh-",
        "outputId": "2cd23fba-8780-4cae-94b0-b449a686305f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Page: Kim Kardashian, Superstar\n",
            "Summary: Kim Kardashian, Superstar (also known simply as Kim K Superstar) is a 2007 pornographic film featuring Kim Kardashian and Ray J. It depicts the pair having sexual intercourse in October 2003 while on vacation in Cabo San Lucas, Mexico. The film brought in more than US$1.4 million in its first six weeks.\n",
            "\n",
            "Page: Kim Kardashian\n",
            "Summary: Kimberly Noel Kardashian (born October 21, 1980) is an American media personality, socialite, and businesswoman. She and her family began to appear on the E! reality television series Keeping Up with the Kardashians after she gained media attention following the release of a sex tape in 2007. The show aired until 2021, and its success led to the formation of several spin-offs and a successor show, Hulu's The Kardashians (2022–present).\n",
            "Kardashian founded KKW Beauty and KKW Fragrance in 2017, both of which operated until 2022; the former was valued at over US$1 billion in 2021. She founded the shaping underwear and foundation garment company Skims in 2019, which is valued at over US$4 billion as of 2023. Following the closure of her cosmetics and fragrance brands, Kardashian founded her skincare line, SKKN by Kim, in 2022. She has released a variety of products tied to her name, including the 2014 mobile game Kim Kardashian: Hollywood, the 2015 photo book Selfish, and the 2015 emoji app Kimoji. Her acting credits include the films Disaster Movie (2008), Temptation: Confessions of a Marriage Counselor (2013), two PAW Patrol films (2021 and 2023), and the twelfth season of the anthology horror series American Horror Story (2023–2024).\n",
            "Time magazine included Kardashian on their list of 2015's 100 most influential people. She was named among Fortune magazine's Most Powerful Women in the world in 2023. With a significant presence online and a large following across numerous social media platforms, she is the seventh-most-followed individual on Instagram and the eleventh-most-followed individual on Twitter. Both critics and admirers have described Kardashian as exemplifying the notion of being famous for being famous. She became a billionaire in 2021, and is estimated by Forbes to be worth US$1.7 billion as of May 2025. Kardashian has become more politically active by lobbying for prison reform and clemency, and, as of 2019, is under a four-year law apprenticeship supervised by the legal nonprofit Cut50.\n",
            "\n",
            "\n",
            "\n",
            "Page: The Kardashians\n",
            "Summary: The Kardashians is an American reality television series focusing on the personal lives of the Kardashian family. The program is a retooled continuation of their previous reality show, Keeping Up with the Kardashians, which concluded in 2021 after a 20-season run, on E!.\n",
            "The series focuses on sisters Kourtney, Kim, and Khloé Kardashian and their half-sisters, Kendall and Kylie Jenner, alongside their mother, Kris Jenner. It has also featured some of their current and former partners across the seasons including Travis Barker, Tristan Thompson, Scott Disick, Corey Gamble, Kanye West, Lamar Odom  and Caitlyn Jenner. A few guest appearances by their friends and celebrities happen occasionally.\n",
            "The Kardashians premiered on April 14, 2022, on the streaming service Hulu; its first season consisted of 10 episodes. Before the series debuted, it was greenlit by Hulu for a multi-season launch with a total of forty episodes. All of the seasons consisted of ten episodes each; the first four premiered bi-annually. The second season premiered in September 2022, followed by the third and fourth seasons in May and September 2023, and the fifth season in May 2024. The Kardashians was renewed for a sixth and seventh season in July 2024; which premiered in February and October 2025 respectively.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##USING DUCKDUCKGO\n"
      ],
      "metadata": {
        "id": "IUx6GnKwshNC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install -U ddgs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 701
        },
        "id": "dJzpmdg2tGeF",
        "outputId": "749bfef6-3335-4f7d-de1e-02f9036ed8ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ddgs\n",
            "  Downloading ddgs-9.8.0-py3-none-any.whl.metadata (18 kB)\n",
            "Requirement already satisfied: click>=8.1.8 in /usr/local/lib/python3.12/dist-packages (from ddgs) (8.3.0)\n",
            "Requirement already satisfied: primp>=0.15.0 in /usr/local/lib/python3.12/dist-packages (from ddgs) (0.15.0)\n",
            "Collecting lxml>=6.0.0 (from ddgs)\n",
            "  Downloading lxml-6.0.2-cp312-cp312-manylinux_2_26_x86_64.manylinux_2_28_x86_64.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: httpx>=0.28.1 in /usr/local/lib/python3.12/dist-packages (from httpx[brotli,http2,socks]>=0.28.1->ddgs) (0.28.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx>=0.28.1->httpx[brotli,http2,socks]>=0.28.1->ddgs) (4.11.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx>=0.28.1->httpx[brotli,http2,socks]>=0.28.1->ddgs) (2025.10.5)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx>=0.28.1->httpx[brotli,http2,socks]>=0.28.1->ddgs) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx>=0.28.1->httpx[brotli,http2,socks]>=0.28.1->ddgs) (3.11)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx>=0.28.1->httpx[brotli,http2,socks]>=0.28.1->ddgs) (0.16.0)\n",
            "Requirement already satisfied: brotli in /usr/local/lib/python3.12/dist-packages (from httpx[brotli,http2,socks]>=0.28.1->ddgs) (1.1.0)\n",
            "Requirement already satisfied: h2<5,>=3 in /usr/local/lib/python3.12/dist-packages (from httpx[brotli,http2,socks]>=0.28.1->ddgs) (4.3.0)\n",
            "Collecting socksio==1.* (from httpx[brotli,http2,socks]>=0.28.1->ddgs)\n",
            "  Downloading socksio-1.0.0-py3-none-any.whl.metadata (6.1 kB)\n",
            "Requirement already satisfied: hyperframe<7,>=6.1 in /usr/local/lib/python3.12/dist-packages (from h2<5,>=3->httpx[brotli,http2,socks]>=0.28.1->ddgs) (6.1.0)\n",
            "Requirement already satisfied: hpack<5,>=4.1 in /usr/local/lib/python3.12/dist-packages (from h2<5,>=3->httpx[brotli,http2,socks]>=0.28.1->ddgs) (4.1.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx>=0.28.1->httpx[brotli,http2,socks]>=0.28.1->ddgs) (1.3.1)\n",
            "Requirement already satisfied: typing_extensions>=4.5 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx>=0.28.1->httpx[brotli,http2,socks]>=0.28.1->ddgs) (4.15.0)\n",
            "Downloading ddgs-9.8.0-py3-none-any.whl (42 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.5/42.5 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading socksio-1.0.0-py3-none-any.whl (12 kB)\n",
            "Downloading lxml-6.0.2-cp312-cp312-manylinux_2_26_x86_64.manylinux_2_28_x86_64.whl (5.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.3/5.3 MB\u001b[0m \u001b[31m23.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: socksio, lxml, ddgs\n",
            "  Attempting uninstall: lxml\n",
            "    Found existing installation: lxml 5.4.0\n",
            "    Uninstalling lxml-5.4.0:\n",
            "      Successfully uninstalled lxml-5.4.0\n",
            "Successfully installed ddgs-9.8.0 lxml-6.0.2 socksio-1.0.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "lxml"
                ]
              },
              "id": "e451ea1478204fc49bddc534a748704d"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.tools import DuckDuckGoSearchRun\n",
        "\n",
        "search_tool = DuckDuckGoSearchRun()\n",
        "\n",
        "results = search_tool.invoke('top news in Banglore today')\n",
        "\n",
        "print(results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AS5AuC7GskFC",
        "outputId": "01de0765-a770-4719-c137-36db4614d30e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Oakridge Weekend Voyagers Workshop in Banglore | Workshops in Bangalore Be A Weekend Voyager- Be the Dream of Every Child.Weekend Voyager is a ... ... include features such as the latest technology in high-speed internet ... This will ensure that you are able to find the top opportunity to invest. Our curated list brings together some of the top SEO companies in Bangalore, each recognized for their expertise, proven track record, and commitment ... Category: Money Making Tags: banglore , banglore jobs , jobs in banglore , make money in banglore , make money online Category: Money Making Tags: banglore , banglore jobs , jobs in banglore , make money in banglore , make money online\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "search_tool.name"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "pem5u2nBvF0A",
        "outputId": "cc1302d4-ac82-4d4f-8f07-70aa9f4c989c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'duckduckgo_search'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "search_tool.description"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "mUFl5tvQvKqX",
        "outputId": "6e010163-0254-485b-aa42-46b76f71f72c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'A wrapper around DuckDuckGo Search. Useful for when you need to answer questions about current events. Input should be a search query.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##USING SERPA-AI(WEBSEARCH)"
      ],
      "metadata": {
        "id": "MGGB4N_utcmz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install google-search-results\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ayOwKIxXtiEq",
        "outputId": "5a18f311-a6c8-4232-bcef-6d40fd31dc12"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: google-search-results in /usr/local/lib/python3.12/dist-packages (2.4.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from google-search-results) (2.32.5)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->google-search-results) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->google-search-results) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->google-search-results) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->google-search-results) (2025.10.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "os.environ[\"SERPAPI_API_KEY\"] = userdata.get('SERPAPI_API_KEY')\n"
      ],
      "metadata": {
        "id": "zGahZEs6twee"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.utilities import SerpAPIWrapper\n",
        "\n",
        "search = SerpAPIWrapper()\n",
        "results = search.run(\"SUPREME COURT AND DOGS IN DELHI\")\n",
        "print(results)\n"
      ],
      "metadata": {
        "id": "H8aqfoq2tkQX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##USING CUSTOM TOOLS :"
      ],
      "metadata": {
        "id": "nw0GuDOvtOiX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "simple example :"
      ],
      "metadata": {
        "id": "QLy2YqxgumAB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "docstrings arent required, however they help improve the quality of your output"
      ],
      "metadata": {
        "id": "5oSW-YxWuqlg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def multiply(a, b):\n",
        "    \"\"\"Multiply two numbers\"\"\"\n",
        "    return a*b"
      ],
      "metadata": {
        "id": "traMgIuatOFL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(multiply.name)\n",
        "print(multiply.description)\n",
        "print(multiply.args)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 183
        },
        "id": "WSfGBBnLu4fr",
        "outputId": "71b8cf34-b52c-4bac-e8cb-f0b4fb1a9183"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'function' object has no attribute 'name'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2466769572.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmultiply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmultiply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdescription\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmultiply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'function' object has no attribute 'name'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##How to not get this error?\n",
        "*   Use Tool\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "vnnTDO2wvUSG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.tools import tool #decorator :"
      ],
      "metadata": {
        "id": "suDzJXpVv9TV"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.tools import Tool\n",
        "def multiply(a:int, b:int) -> int:\n",
        "    return a * b\n",
        "\n",
        "from langchain.tools import Tool\n",
        "multiply_tool = Tool(\n",
        "    name=\"MultiplyTool\",\n",
        "    func=multiply,\n",
        "    description=\"Multiply two numbers.\"\n",
        ")\n"
      ],
      "metadata": {
        "id": "GaLUIuK8wLFi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(multiply_tool.name)\n",
        "print(multiply_tool.description)\n",
        "print(multiply_tool.args)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3P-8Wh0RwA3s",
        "outputId": "47a15c40-c26d-48aa-e1ce-ee1c4ffdedcd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MultiplyTool\n",
            "Multiply two numbers.\n",
            "{'tool_input': {'type': 'string'}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##DEMO OF USING WEATHER API"
      ],
      "metadata": {
        "id": "0qYOTXGmvxTl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# weather_tool.py\n",
        "import requests\n",
        "from langchain.tools import Tool\n",
        "import os\n",
        "\n",
        "WEATHER_KEY = userdata.get(\"WEATHER_API_KEY\")\n",
        "\n",
        "def get_weather(city: str) -> str:\n",
        "    \"\"\"Return a short human-readable weather string for a city.\"\"\"\n",
        "\n",
        "    # Base WeatherAPI endpoint\n",
        "    url = f\"https://api.weatherapi.com/v1/current.json?key={WEATHER_KEY}&q={city}\"\n",
        "\n",
        "\n",
        "    r = requests.get(url, timeout=10)\n",
        "    data = r.json()\n",
        "    temp = data[\"current\"][\"temp_c\"]\n",
        "    cond = data[\"current\"][\"condition\"][\"text\"]\n",
        "\n",
        "    return f\"{city}: {temp}°C, {cond}\"\n",
        "\n",
        "# Wrap as a LangChain Tool\n",
        "weather_tool = Tool(\n",
        "    name=\"WeatherTool\",\n",
        "    func=get_weather,\n",
        "    description=\"Use this to get current weather for a given city. Input should be a city name, e.g. 'Bangalore'.\"\n",
        ")\n"
      ],
      "metadata": {
        "id": "twyjOcdGvwQe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(get_weather(\"Bangalore\"))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iWYbcHWYyGI3",
        "outputId": "cf9c1402-b430-476d-cf8c-f2c093e80fef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bangalore: 20.0°C, Clear\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##TOOLS W LLMS :"
      ],
      "metadata": {
        "id": "D9n21Vfy03cj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "in-built langchain tools can be donw using load_tools"
      ],
      "metadata": {
        "id": "9i0ZofD32j7W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load wikipedia tool via load_tools\n",
        "wiki_tool = load_tools([\"wikipedia\"], llm=llm)\n",
        "\n",
        "#wiki_tool[0].name, wiki_tool[0].description\n",
        "\n",
        "wiki = wiki_tool[0]\n",
        "print(wiki.run(\"LangChain\"))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GP1V2oVkrDA-",
        "outputId": "4a7268ae-c219-4bab-bc6e-27a4fe301878"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Page: LangChain\n",
            "Summary: LangChain is a software framework that helps facilitate the integration of large language models (LLMs) into applications. As a language model integration framework, LangChain's use-cases largely overlap with those of language models in general, including document analysis and summarization, chatbots, and code analysis.\n",
            "\n",
            "\n",
            "\n",
            "Page: Model Context Protocol\n",
            "Summary: The Model Context Protocol (MCP) is an open standard, open-source framework introduced by Anthropic in November 2024 to standardize the way artificial intelligence (AI) systems like large language models (LLMs) integrate and share data with external tools, systems, and data sources. MCP provides a universal interface for reading files, executing functions, and handling contextual prompts. Following its announcement, the protocol was adopted by major AI providers, including OpenAI and Google DeepMind.\n",
            "\n",
            "\n",
            "\n",
            "Page: Milvus (vector database)\n",
            "Summary: Milvus is a distributed vector database developed by Zilliz. It is available as both open-source software and a cloud service called Zilliz Cloud.\n",
            "Milvus is an open-source project under the LF AI & Data Foundation and is distributed under the Apache License 2.0.\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##For custom"
      ],
      "metadata": {
        "id": "i-ZjdO5O2pTQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using prompt based techniques :"
      ],
      "metadata": {
        "id": "_ay-xLjT05vF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.chains import LLMChain\n",
        "from langchain.tools import tool\n",
        "\n",
        "@tool\n",
        "def multiply(a: int, b: int) -> int:\n",
        "    \"\"\"Multiply two numbers.\"\"\"\n",
        "    return a * b\n",
        "\n",
        "prompt = PromptTemplate(\n",
        "    input_variables=[\"query\"],\n",
        "    template=\"\"\"\n",
        "You are a reasoning assistant with access to one tool:\n",
        "Multiply(a,b): multiplies two numbers.\n",
        "\n",
        "When asked a question, respond in JSON like:\n",
        "{{\"tool\": \"Multiply\", \"args\": {{\"a\": <num>, \"b\": <num>}}}}\n",
        "\n",
        "User query: {query}\n",
        "\"\"\"\n",
        ")\n",
        "\n",
        "chain = LLMChain(llm=llm, prompt=prompt)\n",
        "\n",
        "query = \"What is 23 multiplied by 7?\"\n",
        "response = chain.run(query)\n",
        "print(response)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gP9bMWla05O7",
        "outputId": "c77cf856-1689-406c-b8ce-a6870de6e3c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3790150184.py:23: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
            "  chain = LLMChain(llm=llm, prompt=prompt)\n",
            "/tmp/ipython-input-3790150184.py:26: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
            "  response = chain.run(query)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"tool\": \"Multiply\", \"args\": {\"a\": 23, \"b\": 7}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "parsed = json.loads(response)\n",
        "tool_name = parsed[\"tool\"]\n",
        "args = parsed[\"args\"]\n",
        "print(\"Result:\", multiply.invoke(args))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8GMrZ7lz2CxX",
        "outputId": "63722f91-a06e-4e59-ce27-250bcddd8f93"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Result: 161\n"
          ]
        }
      ]
    }
  ]
}